\subsection*{Main research areas}

\subsection*{Model Transformation Languages}
In the scope of model-driven engineering, model transformation aims to provide a mean to specify the way to produce target models from a number of source models. For this purpose, it enables developers to define the way source model elements must be matched and navigated in order to initialize the target model elements. Formally, a model transformation has to define the way for generating a model Mb, conforming to a metamodel MMb, from a model Ma conforming to a metamodel MMa. In practice, model transformations are widely used in model-driven engineering, e.g. during code generation (their originally intended use case), translation among modeling languages, data translation for interoperability, controlled updates over a model at runtime.

I have investigated different paradigms for model transformation, including the relational paradigm (exemplified by the ATL transformation language), the functional paradigm (exemplified by the OCL language), the data-flow paradigm (exemplified by the fUML language). I have studied correspondences between these paradigms and translations among them. 

I have contributed at clarifying the properties of transformation languages, especially bidirectionality (by feature modeling the design space of bidirectional transformations) and recently additivity, a property relating the syntactic constructs of the transformation specification to their semantic output.  
Finally I have distinguished the important class of higher-order transformations, i.e. transformations that manipulate other transformationss

\subsection*{Model Transformation Verification}

With the increasing use of model-driven engineering in safety-critical domains (e.g., in automotive industry, medical data processing, aviation), it is crucial to develop techniques and tools that prevent incorrect model transformations from generating faulty models. The effects of such faulty models could be unpredictably propagated into subsequent MDE steps, e.g. code generation.

For this reason, there is a great need of mechanisms to ensure quality and the absence of errors in models and model transformations. Verification is one of the effective techniques that are typically used to achieve this.

Verification of models and model transformations refers to the ability of these elements to satisfy one or more correctness properties. These properties express certain characteristics that the element under analysis must feature in order to be considered correct. It is typical for verification tools to use formal methods to determine whether the model or model transformation under analysis satisfies the correctness properties under scrutiny.

I have contributed to formalize the execution semantics of the ATL language by translation to the Boogie intermediate verification language. Based on this semantics I have designed a fault localization method, capable of pinpointing the faulty lines of a transformation that does not respect a contracts.

I have designed a new technique for the decomposition of transformation contracts, to improve the efficiency of the automatic verification process on a SMT solver. I have contributed an incremental verification technique, so that after a change to the system, only the impacted part needs to be reverified. This idea greatly increases the applicability of transformation verification in industrial scenarios. 

\subsection*{Scalability of Model-Driven Engineering}
The increasing adoption of Model-Driven Engineering in industrial contexts highlights scalability as a critical limitation. Indeed, several Model-driven tools show critical efficiency limitations in handling very large models (VLMs), e.g. models made by millions of model elements, not unusual in real-life industrial scenarios. Examples of such models appear both at development time, e.g. while reverse-engineering big systems and at runtime, e.g. coming from a set of sensors, from OpenData repositories or when building applications on social networks. Moreover, the proliferation of models produced as input-outputs of software engineering tasks at development/maintenance time also highlights scalability problems in the management of the model artifacts.

In order to tackle the scalability problem I research solutions on three main axes:

\begin{itemize}

\item Efficient Transformation. Performing only the strictly required computation on models improves scalability, as only parts of VLM need to be loaded and manipulated. I provided the following support for the efficient execution of model-to-model transformations:
1) An engine for the incremental execution of model-to-model transformations, performing only the necessary re-computations; 2) A lazy execution semantics for model transformations, delaying the computation to when it is strictly needed; 3) An engine for the event-driven reactive execution of model transformations, where the engine performs only the computation needed to react to model updates and requests from the user application.

\item Parallel Transformation. The previous techniques increase efficiency by avoiding unnecessary computation. However, this is not always possible, as several transformations perform global algorithms on the whole model. In this scenario, a solution for the scalability problem would be the parallelization of the transformation with the aim of  decomposing it in smaller independent problems, more easily manageable with current tools. In this context, I conceived 1) A shared-memory implicit parallel execution engine for the ATL transformation language and 2) A distributed framework for model transformation on the Map-Reduce programming model. In particular automatic model distribution is performed within the cluster, by a streaming partitioning algorithm over the input model.

\item Efficient Model Persistence. Very large models need high-performance mechanism for their storage and access. Traditional approaches are file-based, especially XML-based, or rely on relational databases. I investigated innovative mechanisms for model storage, by relying on map-databases, graph-databases and distributed hash-tables. These approches have recently converged in the NeoEMF model persistence tool.

\end{itemize}
